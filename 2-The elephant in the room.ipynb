{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop\n",
    "## The elephant in the room\n",
    "---\n",
    "\n",
    "<img src='img/hadoop.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto que el modelo de programación **MapReduce** proporciona al usuario la capacidad de realizar operaciones sencillas sobre grandes volumenes de datos usando conjuntos de máquinas, o clusters.\n",
    "\n",
    "Inicialmente, uno de los principales inconvenientes de MapReduce es que solo estaba disponible para los ingenieros de Google. \n",
    "\n",
    "Por otro lado, **Doug Cutting y Mike Cafarella** estaban en proceso de desarrollar un motor de busqueda que fuese capaz de indexar 1 billon de paginas (Apache Nutch) en el menor tiempo posible. Cómo prueba de concepto fue un éxito, pero pronto se dieron cuenta de que la arquitectura que usaba el motor no estaba preparada para utilizar múltiples máquinas. Ante el reto que suponia la utilización de recursos de forma distribuída, necesitaban algo que pudiera resolver el problema de escalabilidad de forma independiente para poder centrarse en el problema central de indexar de internet.\n",
    "\n",
    "Afortunadamente, entre el año 2003 y 2004, Google pública dos articulos que pondrían solución a los problemas de Doug y Mike: el [google file system](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf) y el de [MapReduce](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf).\n",
    "\n",
    "En estos artículos, se describe la arquitectura del sistema de ficheros distribuídos de Google y un paradigma de programación que sacaba el mejor partido a la naturaleza distribuída del GFS. Finalmente, estos dos artículos dieron lugar a la fundación de lo que hoy se conoce como **Hadoop**.\n",
    "\n",
    "<img src='img/hadoop-timeline.png' width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura\n",
    "---\n",
    "\n",
    "1. **Hadoop Common:** Librerías y utilidades que requieren los otros módulos de Hadoop. Proveen abstracciones a nivel de sistemas de ficheros y sistema operativo para poder utilizar el framework.\n",
    "\n",
    "1. **Hadoop YARN:** Yet Another Resource Negotiator, es una tecnología que permite administrar clusters.\n",
    "\n",
    "1. **Hadoop Distributed File System (HDFS™):** Sistema distribuido de ficheros que permite guardar datos de forma distribuída y con tolerancia a fallos por redundancia. \n",
    "\n",
    "1. **Hadoop MapReduce:** Sistema de procesado en paralelo de grandes conjuntos de datos basado en YARN\n",
    "\n",
    "<img src='img/hadoop-arch.png' width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HDFS\n",
    "---\n",
    "HDFS (Hadoop Distributed File System) esta diseñado para ser tolerante a fallos y usarse sobre hardware de bajo coste. Para guardar los datos, los ficheros se distribuyen en multiples nodos de forma redundante para evitar pérdidas de información en caso de fallo del disco. Su naturaleza distribuída permite una la realización de cálculos de forma paralela.\n",
    "\n",
    "AL guardar un fichero, HDFS divide los nodos de forma que uno es el *namenode* y el resto son *data nodes*. La forma de guardado es dividiendo el fichero en múltiples trozos de 64 MB (chunks) que se distribuyen de forma redundante en los *data nodes*. La información, o mejor dicho, la meta-información de cómo esta distribuído el fichero en éste sistema se maneja a traves del *namenode*, que *datanode* tiene que *chunk* y sobre que otros nodos está ese trozo de fichero, de forma que si un nodo falla el sistema sepa dónde ir a buscar la réplica.\n",
    "\n",
    "<img src='img/hdfs_architecture.jpg' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecosistema\n",
    "---\n",
    "Desde el primer momento, Hadoop tuvo una gran adopción en el mundo empresarial ya que dotaba de una infraestructura facil de usar y potente para manejar grandes volúmenes de datos.\n",
    "\n",
    "En paralelo a la continua mejora de Hadoop, distintas tecnologías han aparecido con tal de acercar al usuario final la potencia del procesamiento de datos de forma distribuída de forma cada vez más sencilla.\n",
    "\n",
    "Actualmente, el ecosistema de tecnologías que potencian o complementan las características de Hadoop, tiene esta pinta:\n",
    "\n",
    "<img src='img/HadoopStack.png' width=700>\n",
    "\n",
    "### Ingesta\n",
    "\n",
    "<span style='color:green'>**Kafka:**</span> La manipulación en tiempo real de fuentes de datos (multi-consumo)\n",
    "\n",
    "**scoop**: transferir datos entre bases de datos relacionales y Hadoop.\n",
    "\n",
    "**Flume**: ingesta de grandes cantidades de registros de log en tiempo real (soporte comercial)\n",
    "\n",
    "### Bases de datos no relacionales\n",
    "\n",
    "**Hbase, Cassandra**, <span style='color:green'>**MongoDB**</span>\n",
    "\n",
    "Las bases de datos no relacionales ofrecen una escalabilidad casi lineal.\n",
    "\n",
    "Para más info, echadle un vistazo a esta comparación de las bases de datos no relacionales más populares y sus casos de uso: [comparación NoSQL](https://www.linkedin.com/pulse/real-comparison-nosql-databases-hbase-cassandra-mongodb-sahu/)\n",
    "\n",
    "\n",
    "### Consumo\n",
    "\n",
    "**Pig**: Más usado por ingenieros de datos. Da una mayor versatilidad para procesos ETL.\n",
    "\n",
    "<span style='color:green'>**Hive**:</span>: Más usado por analistas. Interfaz tipo SQL para crear tareas de MapReduce sobre Hadoop.\n",
    "\n",
    "**Mahout**: Machine learning escalable. Proyecto muy maduro con [casos reales de éxito](https://mahout.apache.org/general/powered-by-mahout.html)\n",
    "\n",
    "<span style='color:green'>**Spark**:</span> Es toda una infraestructura que permite el procesado de grandes volumenes de datos con funcionalidades de streaming (casi a tiempo real), machine learning, procesamiento de grafos y SQL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Resumiendo...\n",
    "\n",
    "Hadoop es una infraestructura clave en el mundo del Big Data. Permite al usuario procesar grandes volumenes de datos de forma rápida y eficiente gracias a su naturaleza distribuída.\n",
    "\n",
    "Una de las mayores ventajas de Hadoop es que no se basa en una maquinaria específica para proveer una alta tolerancia a los fallos, si no que ha sido diseñado con el concepto de que la maquinaria falla tarde o temprano y que es mejor confiar en tener varias copias de los datos. De esta forma, la capa de aplicación se encarga de detectar y manejar los errores.\n",
    "\n",
    "Hadoop es muy versatil en el sentido de que se pueden añadir y quitar servidores de forma dinámica sin interrupción de la infraestructura.\n",
    "\n",
    "Finalmente, al estar escrito en Java, es multiplataforma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
